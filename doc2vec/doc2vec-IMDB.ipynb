{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Doc2vec Tutorial on the IMDB Sentiment Dataset\n",
    "This notebook is modified based on the original one provided by Gensim.  \n",
    "You can find it here: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this tutorial, we will learn how to apply Doc2vec using gensim by recreating the results of <a href=\"https://arxiv.org/pdf/1405.4053.pdf\">Le and Mikolov 2014</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words Model\n",
    "\n",
    "Previous state-of-the-art document representations were based on the <a href=\"https://en.wikipedia.org/wiki/Bag-of-words_model\">bag-of-words model</a>, which represent input documents as a fixed-length vector. For example, borrowing from the Wikipedia article, the two documents  \n",
    "  \n",
    "(1) `John likes to watch movies. Mary likes movies too.`  \n",
    "(2) `John also likes to watch football games.`  \n",
    "  \n",
    "are used to construct a length 10 list of words  \n",
    "  \n",
    "`[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\"]`  \n",
    "  \n",
    "so then we can represent the two documents as **fixed length vectors** whose elements are the frequencies of the corresponding words in our list  \n",
    "  \n",
    "(1) `[1, 2, 1, 1, 2, 1, 1, 0, 0, 0]`  \n",
    "(2) `[1, 1, 1, 1, 0, 0, 0, 1, 1, 1]`  \n",
    "  \n",
    "Bag-of-words models are surprisingly effective but still **lose information about word order**.  \n",
    "Bag of <a href=\"https://en.wikipedia.org/wiki/N-gram\">n-grams</a> models consider **word phrases of length n** to represent documents as fixed-length vectors to capture local word order but suffer from data sparsity and high dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec Model\n",
    "\n",
    "Word2vec is a more recent model that embeds words in a high-dimensional vector space using a shallow neural network.  \n",
    "The result is a set of word vectors where vectors close together in vector space have similar meanings based on context, and word vectors distant to each other have differing meanings.  \n",
    "For example, `strong` and `powerful` would be close together and `strong` and `Paris` would be relatively far.  \n",
    "There are two versions of this model based on skip-grams and continuous bag of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec - Skip-gram Model\n",
    "\n",
    "The skip-gram <a href=\"http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\">word2vec</a> model, for example, takes in **pairs (word1, word2)** generated by moving a window across text data, and trains a **1-hidden-layer neural network** based on the fake task of given an input word, giving us a predicted probability distribution of nearby words to the input.  \n",
    "The **hidden-to-output weights** in the neural network give us the word embeddings. So if the hidden layer has 300 neurons, this network will give us 300-dimensional word embeddings. We use <a href=\"https://en.wikipedia.org/wiki/One-hot\">one-hot</a> encoding for the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec - Continuous-bag-of-words Model\n",
    "\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It is also a **1-hidden-layer neural network**.  \n",
    "The fake task is based on the input context words in a window around a center word, predict the center word. Again, the **hidden-to-output weights** give us the word embeddings and we use one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph Vector\n",
    "\n",
    "Le and Mikolov 2014 introduces the **Paragraph Vector**, which outperforms more naÃ¯ve representations of documents such as averaging the Word2vec word vectors of a document.  \n",
    "The idea is straightforward: we act as if **a paragraph (or document) is just another vector** like a word vector, but we will call it a paragraph vector.  \n",
    "We determine the embedding of the paragraph in vector space in the same way as words. Our paragraph vector model **considers local word order like bag of n-grams**, but gives us a denser representation in vector space compared to a sparse, high-dimensional representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paragraph Vector - Distributed Memory (PV-DM)\n",
    "\n",
    "This is the Paragraph Vector model analogous to **Continuous-bag-of-words Word2vec**.  \n",
    "The paragraph vectors are obtained by **training a neural network on the fake task of inferring a center word based on context words and a context paragraph**. A paragraph is a context for all words in the paragraph, and a word in a paragraph can have that paragraph as a context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paragraph Vector - Distributed Bag of Words (PV-DBOW)\n",
    "\n",
    "This is the Paragraph Vector model analogous to **Skip-gram Word2vec**.  \n",
    "The paragraph vectors are obtained by training a neural network on the **fake task of predicting a probability distribution of words in a paragraph given a randomly-sampled word from the paragraph**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "The following python modules are dependencies for this tutorial:\n",
    "* testfixtures ( `pip install testfixtures` )\n",
    "* statsmodels ( `pip install statsmodels` )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the IMDB archive if it is not already downloaded (84 MB). This will be our text data for this tutorial.   \n",
    "The data can be found here: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "import glob\n",
    "import os.path\n",
    "import requests\n",
    "import tarfile\n",
    "import sys\n",
    "import codecs\n",
    "import smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'aclImdb'\n",
    "filename = 'aclImdb_v1.tar.gz'\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "if sys.version > '3':\n",
    "    control_chars = [chr(0x85)]\n",
    "else:\n",
    "    control_chars = [unichr(0x85)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert text to lower-case and strip punctuation/symbols from words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    # Replace breaks with spaces\n",
    "    norm_text = norm_text.replace('<br />', ' ')\n",
    "    # Pad punctuation with spaces on both sides\n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
    "        norm_text = norm_text.replace(char, ' ' + char + ' ')\n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "\n",
    "if not os.path.isfile('aclImdb/alldata-id.txt'):\n",
    "    if not os.path.isdir(dirname):\n",
    "        if not os.path.isfile(filename):\n",
    "            # Download IMDB archive\n",
    "            print(\"Downloading IMDB archive...\")\n",
    "            url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
    "            r = requests.get(url)\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        tar = tarfile.open(filename, mode='r')\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "    # Concatenate and normalize test/train data\n",
    "    print(\"Cleaning up dataset...\")\n",
    "    folders = ['train/pos', 'train/neg', 'test/pos', 'test/neg', 'train/unsup']\n",
    "    alldata = u''\n",
    "    for fol in folders:\n",
    "        temp = u''\n",
    "        output = fol.replace('/', '-') + '.txt'\n",
    "        # Is there a better pattern to use?\n",
    "        txt_files = glob.glob(os.path.join(dirname, fol, '*.txt'))\n",
    "        for txt in txt_files:\n",
    "            with smart_open.smart_open(txt, \"rb\") as t:\n",
    "                t_clean = t.read().decode(\"utf-8\")\n",
    "                for c in control_chars:\n",
    "                    t_clean = t_clean.replace(c, ' ')\n",
    "                temp += t_clean\n",
    "            temp += \"\\n\"\n",
    "        temp_norm = normalize_text(temp)\n",
    "        with smart_open.smart_open(os.path.join(dirname, output), \"wb\") as n:\n",
    "            n.write(temp_norm.encode(\"utf-8\"))\n",
    "        alldata += temp_norm\n",
    "\n",
    "    with smart_open.smart_open(os.path.join(dirname, 'alldata-id.txt'), 'wb') as f:\n",
    "        for idx, line in enumerate(alldata.splitlines()):\n",
    "            num_line = u\"_*{0} {1}\\n\".format(idx, line)\n",
    "            f.write(num_line.encode(\"utf-8\"))\n",
    "\n",
    "end = time.clock()\n",
    "print (\"Total running time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "assert os.path.isfile(\"../../gensim_word2vec/aclImdb/alldata-id.txt\"), \"alldata-id.txt unavailable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data is small enough to be read into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []  # Will hold all docs in original order\n",
    "with open('../../gensim_word2vec/aclImdb/alldata-id.txt') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        words = tokens[1:]\n",
    "        tags = [line_no] # 'tags = [tokens[0]]' would also work at extra memory cost\n",
    "        split = ['train', 'test', 'extra', 'extra'][line_no//25000]  # 25k train, 25k test, 25k extra\n",
    "        sentiment = [1.0, 0.0, 1.0, 0.0, None, None, None, None][line_no//12500] # [12.5K pos, 12.5K neg]*2 then unknown\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n"
     ]
    }
   ],
   "source": [
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "doc_list = alldocs[:]  # For reshuffling per pass\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(doc_list), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentDocument(words=[u'sudden', u'impact', u'is', u'the', u'best', u'of', u'the', u'five', u'dirty', u'harry', u'movies', u'.', u'they', u\"don't\", u'come', u'any', u'leaner', u'and', u'meaner', u'than', u'this', u'as', u'harry', u'romps', u'through', u'a', u'series', u'of', u'violent', u'clashes', u',', u'with', u'the', u'bad', u'guys', u'getting', u'their', u'just', u'desserts', u'.', u'which', u'is', u'just', u'the', u'way', u'i', u'like', u'it', u'.', u'great', u'story', u'too', u'and', u'ably', u'directed', u'by', u'clint', u'himself', u'.', u'excellent', u'entertainment', u'.'], tags=[0], split='train', sentiment=1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up Doc2Vec Training & Evaluation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate the experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf) with guidance from Mikolov's [example go.sh](https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ):\n",
    "\n",
    "`./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1`\n",
    "\n",
    "We vary the following parameter choices:\n",
    "* **100-dimensional** vectors, as the 400-d vectors of the paper don't seem to offer much benefit on this task\n",
    "* Similarly, **frequent word subsampling** seems to decrease sentiment-prediction accuracy, so it's left out\n",
    "* `cbow=0` means skip-gram which is equivalent to the paper's 'PV-DBOW' mode, matched in gensim with `dm=0`\n",
    "* Added to that DBOW model are two DM models, one which averages context vectors (`dm_mean`) and one which concatenates them (`dm_concat`, resulting in a much larger, slower, more data-hungry model)\n",
    "* A `min_count=2` saves quite a bit of model memory, discarding only words that appear in a single doc (and are thus no more expressive than the unique-to-each doc vectors themselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test 3 simple models here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_models = [\n",
    "    # PV-DM w/ concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, size=100, window=5, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DBOW \n",
    "    Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores),\n",
    "    # PV-DM w/ average\n",
    "    Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed up setup by sharing results of the 1st model's vocabulary scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it turns out that, sometime the intersect could be quite low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.92 s, sys: 133 ms, total: 7.05 s\n",
      "Wall time: 6.95 s\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)\n"
     ]
    }
   ],
   "source": [
    "# PV-DM w/ concat requires one special NULL word so it serves as template\n",
    "%time simple_models[0].build_vocab(alldocs)  \n",
    "print(simple_models[0])\n",
    "for model in simple_models[1:]:\n",
    "    model.reset_from(simple_models[0])\n",
    "    print(model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116046\n"
     ]
    }
   ],
   "source": [
    "print(len(simple_models[0].wv.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le and Mikolov notes that **combining a paragraph vector from Distributed Bag of Words (DBOW) and Distributed Memory (DM) improves performance**.  \n",
    "We will follow, pairing the models together for evaluation. Here, **we concatenate the paragraph vectors obtained from each model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[2]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[1], simple_models[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)',\n",
       "              <gensim.models.doc2vec.Doc2Vec at 0x7f66224adf10>),\n",
       "             ('Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)',\n",
       "              <gensim.models.doc2vec.Doc2Vec at 0x7f66224adfd0>),\n",
       "             ('Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)',\n",
       "              <gensim.models.doc2vec.Doc2Vec at 0x7f66223e80d0>),\n",
       "             ('dbow+dmm',\n",
       "              <gensim.test.test_doc2vec.ConcatenatedDoc2Vec at 0x7f6684bc5850>),\n",
       "             ('dbow+dmc',\n",
       "              <gensim.test.test_doc2vec.ConcatenatedDoc2Vec at 0x7f661ef47490>)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_by_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some helper methods for evaluating the performance of our Doc2vec using paragraph vectors.  \n",
    "We will classify document sentiments using a **logistic regression** model based on our paragraph embeddings.  \n",
    "We will compare the error rates based on word embeddings from our various Doc2vec models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saucecat/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from timeit import default_timer\n",
    "import time \n",
    "\n",
    "@contextmanager\n",
    "def elapsed_timer():\n",
    "    start = default_timer()\n",
    "    elapser = lambda: default_timer() - start\n",
    "    yield lambda: elapser()\n",
    "    end = default_timer()\n",
    "    elapser = lambda: end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "    logit = sm.Logit(train_targets, train_regressors)\n",
    "    predictor = logit.fit(disp=0)\n",
    "    #print(predictor.summary())\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate_for_model(test_model, train_set, test_set, infer=False, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets, train_regressors = zip(*[(doc.sentiment, test_model.docvecs[doc.tags[0]]) for doc in train_set])\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "    \n",
    "    # Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_data])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an explicit multiple-pass, alpha-reduction approach as sketched in this [gensim doc2vec blog post](http://radimrehurek.com/2014/12/doc2vec-tutorial/) with added shuffling of corpus on each pass.  \n",
    "Note that vector training is occurring on **all** documents of the dataset, which includes all **TRAIN/TEST/DEV** docs.  \n",
    "We evaluate each model's sentiment predictive power based on error rate, and **the evaluation is repeated after each pass** so we can see the rates of relative improvement. The base numbers reuse the TRAIN and TEST vectors stored in the models for the logistic regression, while the _inferred_ results use newly-inferred TEST vectors. \n",
    "\n",
    "**(On a 4-core 2.6Ghz Intel Core i7, these 20 passes training and evaluating 3 main models takes about an hour.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "best_error = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START 2018-01-26 10:48:29.687572\n",
      "*0.406120 : 1 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 36.1s 1.0s\n",
      "*0.345200 : 1 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_inferred 36.1s 8.0s\n",
      "*0.243600 : 1 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 17.7s 0.7s\n",
      "*0.181200 : 1 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_inferred 17.7s 2.9s\n",
      "*0.261920 : 1 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.1s 0.7s\n",
      "*0.212400 : 1 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_inferred 18.1s 3.4s\n",
      "*0.213680 : 1 passes : dbow+dmm 0.0s 1.6s\n",
      "*0.169200 : 1 passes : dbow+dmm_inferred 0.0s 6.3s\n",
      "*0.241280 : 1 passes : dbow+dmc 0.0s 1.6s\n",
      "*0.197200 : 1 passes : dbow+dmc_inferred 0.0s 10.6s\n",
      "Completed pass 1 at alpha 0.025000\n",
      "*0.344880 : 2 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 33.3s 0.6s\n",
      "*0.143680 : 2 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.4s 0.6s\n",
      "*0.212400 : 2 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.7s 0.7s\n",
      "*0.136640 : 2 passes : dbow+dmm 0.0s 1.7s\n",
      "*0.143200 : 2 passes : dbow+dmc 0.0s 2.0s\n",
      "Completed pass 2 at alpha 0.023800\n",
      "*0.306760 : 3 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 33.5s 0.7s\n",
      "*0.125680 : 3 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.1s 0.8s\n",
      "*0.189160 : 3 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 19.1s 0.8s\n",
      "*0.121800 : 3 passes : dbow+dmm 0.0s 1.9s\n",
      "*0.125200 : 3 passes : dbow+dmc 0.0s 1.9s\n",
      "Completed pass 3 at alpha 0.022600\n",
      "*0.277480 : 4 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 33.2s 0.7s\n",
      "*0.115280 : 4 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.2s 1.1s\n",
      "*0.178320 : 4 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 19.1s 0.7s\n",
      "*0.114160 : 4 passes : dbow+dmm 0.0s 1.8s\n",
      "*0.115680 : 4 passes : dbow+dmc 0.0s 1.8s\n",
      "Completed pass 4 at alpha 0.021400\n",
      "*0.251520 : 5 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 33.0s 0.7s\n",
      "*0.260800 : 5 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_inferred 33.0s 7.9s\n",
      "*0.112800 : 5 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.2s 0.8s\n",
      "*0.119600 : 5 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_inferred 16.2s 3.3s\n",
      "*0.171280 : 5 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 19.3s 0.8s\n",
      "*0.194000 : 5 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_inferred 19.3s 3.5s\n",
      "*0.109680 : 5 passes : dbow+dmm 0.0s 1.8s\n",
      "*0.112000 : 5 passes : dbow+dmm_inferred 0.0s 6.9s\n",
      "*0.111080 : 5 passes : dbow+dmc 0.0s 1.9s\n",
      "*0.126400 : 5 passes : dbow+dmc_inferred 0.0s 11.4s\n",
      "Completed pass 5 at alpha 0.020200\n",
      "*0.233280 : 6 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 32.5s 1.0s\n",
      "*0.108960 : 6 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.166920 : 6 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.7s 0.7s\n",
      "*0.108160 : 6 passes : dbow+dmm 0.0s 1.7s\n",
      "*0.109160 : 6 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 6 at alpha 0.019000\n",
      "*0.219120 : 7 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 31.3s 0.7s\n",
      "*0.106960 : 7 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.164160 : 7 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.7s 1.0s\n",
      "*0.105520 : 7 passes : dbow+dmm 0.0s 2.0s\n",
      "*0.106760 : 7 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 7 at alpha 0.017800\n",
      "*0.208400 : 8 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 31.1s 0.7s\n",
      "*0.106920 : 8 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.8s 0.7s\n",
      "*0.160000 : 8 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.105400 : 8 passes : dbow+dmm 0.0s 2.0s\n",
      "*0.106480 : 8 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 8 at alpha 0.016600\n",
      "*0.201800 : 9 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.9s 0.7s\n",
      "*0.105360 : 9 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.0s 0.7s\n",
      "*0.158600 : 9 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.104480 : 9 passes : dbow+dmm 0.0s 1.7s\n",
      "*0.104240 : 9 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 9 at alpha 0.015400\n",
      "*0.194640 : 10 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.7s 1.0s\n",
      "*0.194000 : 10 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_inferred 30.7s 7.5s\n",
      " 0.106080 : 10 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.114800 : 10 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_inferred 15.9s 2.8s\n",
      "*0.155960 : 10 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.191600 : 10 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_inferred 18.8s 3.3s\n",
      " 0.105760 : 10 passes : dbow+dmm 0.0s 1.7s\n",
      " 0.113200 : 10 passes : dbow+dmm_inferred 0.0s 6.7s\n",
      " 0.104880 : 10 passes : dbow+dmc 0.0s 1.7s\n",
      "*0.105200 : 10 passes : dbow+dmc_inferred 0.0s 10.4s\n",
      "Completed pass 10 at alpha 0.014200\n",
      "*0.192000 : 11 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.3s 0.8s\n",
      "*0.105080 : 11 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.154520 : 11 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      " 0.104600 : 11 passes : dbow+dmm 0.0s 1.7s\n",
      " 0.104360 : 11 passes : dbow+dmc 0.0s 2.0s\n",
      "Completed pass 11 at alpha 0.013000\n",
      "*0.187880 : 12 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.4s 0.7s\n",
      "*0.104760 : 12 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.153080 : 12 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.104200 : 12 passes : dbow+dmm 0.0s 1.7s\n",
      "*0.104240 : 12 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 12 at alpha 0.011800\n",
      "*0.186000 : 13 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.3s 0.7s\n",
      "*0.103880 : 13 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.0s 1.0s\n",
      "*0.152280 : 13 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.103880 : 13 passes : dbow+dmm 0.0s 1.8s\n",
      "*0.103400 : 13 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 13 at alpha 0.010600\n",
      "*0.183360 : 14 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.1s 0.7s\n",
      " 0.104120 : 14 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.8s 0.7s\n",
      "*0.152000 : 14 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.103600 : 14 passes : dbow+dmm 0.0s 2.0s\n",
      "*0.103240 : 14 passes : dbow+dmc 0.0s 1.6s\n",
      "Completed pass 14 at alpha 0.009400\n",
      "*0.181400 : 15 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 30.0s 0.7s\n",
      " 0.200800 : 15 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_inferred 30.0s 7.4s\n",
      " 0.103920 : 15 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.0s 0.7s\n",
      " 0.114800 : 15 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_inferred 16.0s 2.8s\n",
      "*0.151000 : 15 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.186400 : 15 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_inferred 18.8s 3.6s\n",
      "*0.103480 : 15 passes : dbow+dmm 0.0s 1.7s\n",
      "*0.111200 : 15 passes : dbow+dmm_inferred 0.0s 6.4s\n",
      " 0.103520 : 15 passes : dbow+dmc 0.0s 1.7s\n",
      "*0.101600 : 15 passes : dbow+dmc_inferred 0.0s 10.5s\n",
      "Completed pass 15 at alpha 0.008200\n",
      "*0.179480 : 16 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 29.6s 0.7s\n",
      "*0.103800 : 16 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      " 0.151120 : 16 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.7s 1.0s\n",
      "*0.102600 : 16 passes : dbow+dmm 0.0s 1.8s\n",
      " 0.103520 : 16 passes : dbow+dmc 0.0s 1.5s\n",
      "Completed pass 16 at alpha 0.007000\n",
      "*0.179120 : 17 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 29.9s 0.7s\n",
      "*0.103200 : 17 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 16.0s 0.7s\n",
      " 0.151240 : 17 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      "*0.101680 : 17 passes : dbow+dmm 0.0s 2.0s\n",
      " 0.103800 : 17 passes : dbow+dmc 0.0s 1.6s\n",
      "Completed pass 17 at alpha 0.005800\n",
      "*0.177240 : 18 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 29.7s 0.7s\n",
      " 0.103720 : 18 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.150720 : 18 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.7s 0.7s\n",
      " 0.102600 : 18 passes : dbow+dmm 0.0s 1.9s\n",
      " 0.103760 : 18 passes : dbow+dmc 0.0s 1.8s\n",
      "Completed pass 18 at alpha 0.004600\n",
      "*0.176600 : 19 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 29.6s 1.0s\n",
      " 0.103720 : 19 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 0.7s\n",
      "*0.150200 : 19 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      " 0.102320 : 19 passes : dbow+dmm 0.0s 1.7s\n",
      "*0.102840 : 19 passes : dbow+dmc 0.0s 1.7s\n",
      "Completed pass 19 at alpha 0.003400\n",
      "*0.176000 : 20 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) 29.5s 0.7s\n",
      "*0.184400 : 20 passes : Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_inferred 29.5s 7.3s\n",
      " 0.103440 : 20 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) 15.9s 1.0s\n",
      "*0.105600 : 20 passes : Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_inferred 15.9s 2.8s\n",
      "*0.149680 : 20 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) 18.8s 0.7s\n",
      " 0.191600 : 20 passes : Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_inferred 18.8s 3.3s\n",
      " 0.102360 : 20 passes : dbow+dmm 0.0s 1.8s\n",
      " 0.116400 : 20 passes : dbow+dmm_inferred 0.0s 6.5s\n",
      " 0.103320 : 20 passes : dbow+dmc 0.0s 1.7s\n",
      " 0.109200 : 20 passes : dbow+dmc_inferred 0.0s 10.6s\n",
      "Completed pass 20 at alpha 0.002200\n",
      "END 2018-01-26 11:15:04.241652\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import datetime\n",
    "\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "print(\"START %s\" % datetime.datetime.now())\n",
    "\n",
    "for epoch in range(passes):\n",
    "    shuffle(doc_list)  # Shuffling gets best results\n",
    "    \n",
    "    for name, train_model in models_by_name.items():\n",
    "        # Train\n",
    "        duration = 'na'\n",
    "        train_model.alpha, train_model.min_alpha = alpha, alpha\n",
    "        with elapsed_timer() as elapsed:\n",
    "            train_model.train(doc_list, total_examples=len(doc_list), epochs=1)\n",
    "            duration = '%.1f' % elapsed()\n",
    "            \n",
    "        # Evaluate\n",
    "        eval_duration = ''\n",
    "        with elapsed_timer() as eval_elapsed:\n",
    "            err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs)\n",
    "        eval_duration = '%.1f' % eval_elapsed()\n",
    "        best_indicator = ' '\n",
    "        if err <= best_error[name]:\n",
    "            best_error[name] = err\n",
    "            best_indicator = '*' \n",
    "        print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, err, epoch + 1, name, duration, eval_duration))\n",
    "\n",
    "        if ((epoch + 1) % 5) == 0 or epoch == 0:\n",
    "            eval_duration = ''\n",
    "            with elapsed_timer() as eval_elapsed:\n",
    "                infer_err, err_count, test_count, predictor = error_rate_for_model(train_model, train_docs, test_docs, infer=True)\n",
    "            eval_duration = '%.1f' % eval_elapsed()\n",
    "            best_indicator = ' '\n",
    "            if infer_err < best_error[name + '_inferred']:\n",
    "                best_error[name + '_inferred'] = infer_err\n",
    "                best_indicator = '*'\n",
    "            print(\"%s%f : %i passes : %s %ss %ss\" % (best_indicator, infer_err, epoch + 1, name + '_inferred', duration, eval_duration))\n",
    "\n",
    "    print('Completed pass %i at alpha %f' % (epoch + 1, alpha))\n",
    "    alpha -= alpha_delta\n",
    "    \n",
    "print(\"END %s\" % str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieved Sentiment-Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err rate Model\n",
      "0.101600 dbow+dmc_inferred\n",
      "0.101680 dbow+dmm\n",
      "0.102840 dbow+dmc\n",
      "0.103200 Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)\n",
      "0.105600 Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_inferred\n",
      "0.111200 dbow+dmm_inferred\n",
      "0.149680 Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)\n",
      "0.176000 Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)\n",
      "0.184400 Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_inferred\n",
      "0.186400 Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_inferred\n"
     ]
    }
   ],
   "source": [
    "# Print best error rates achieved\n",
    "print(\"Err rate Model\")\n",
    "for rate, name in sorted((rate, name) for name, rate in best_error.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_error_rate_for_model(clf, test_model, name, train_set, test_set, infer_steps=3, infer_alpha=0.1, infer_subsample=0.1):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "    \n",
    "    train_targets = np.array([doc.sentiment for doc in train_set])\n",
    "    train_feats = np.array([test_model.docvecs[doc.tags[0]] for doc in train_set])\n",
    "    \n",
    "    clf.fit(train_feats, train_targets)\n",
    "\n",
    "    test_data = test_set\n",
    "    if infer_subsample < 1.0:\n",
    "        test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        \n",
    "    test_feats_infer = np.array([test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data])\n",
    "    test_feats = np.array([test_model.docvecs[doc.tags[0]] for doc in test_data])\n",
    "    \n",
    "    # Predict & evaluate\n",
    "    for feats_name, feats in zip(['', '_infer'], [test_feats, test_feats_infer]):\n",
    "        test_predictions = clf.predict(feats)\n",
    "        test_probs = clf.predict_proba(feats)[:, 1]\n",
    "        test_true = np.array([doc.sentiment for doc in test_data])\n",
    "        acc_rate = np.mean(test_predictions==test_true)\n",
    "        roc = roc_auc_score(test_true, test_probs)\n",
    "        print(\"%s : acc rate: %f  auc_roc: %f\" % (name + feats_name, acc_rate, roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) : acc rate: 0.769200  auc_roc: 0.864437\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_infer : acc rate: 0.750400  auc_roc: 0.837426\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) : acc rate: 0.852400  auc_roc: 0.927155\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_infer : acc rate: 0.852000  auc_roc: 0.927317\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) : acc rate: 0.825600  auc_roc: 0.901677\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_infer : acc rate: 0.788800  auc_roc: 0.869700\n",
      "dbow+dmm : acc rate: 0.866000  auc_roc: 0.940335\n",
      "dbow+dmm_infer : acc rate: 0.852000  auc_roc: 0.932618\n",
      "dbow+dmc : acc rate: 0.867600  auc_roc: 0.945008\n",
      "dbow+dmc_infer : acc rate: 0.863200  auc_roc: 0.941105\n"
     ]
    }
   ],
   "source": [
    "for name, train_model in models_by_name.items():\n",
    "    xgb_clf = xgb.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=100, objective='binary:logistic', \n",
    "                                subsample=0.85, colsample_bytree=0.85, colsample_bylevel=0.85)\n",
    "    clf_error_rate_for_model(xgb_clf, train_model, name, train_docs, test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) : acc rate: 0.756000  auc_roc: 0.828077\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_infer : acc rate: 0.743200  auc_roc: 0.816011\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) : acc rate: 0.828800  auc_roc: 0.909808\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_infer : acc rate: 0.821200  auc_roc: 0.905437\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) : acc rate: 0.779200  auc_roc: 0.856277\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_infer : acc rate: 0.742800  auc_roc: 0.816159\n",
      "dbow+dmm : acc rate: 0.826400  auc_roc: 0.902402\n",
      "dbow+dmm_infer : acc rate: 0.811200  auc_roc: 0.890690\n",
      "dbow+dmc : acc rate: 0.815600  auc_roc: 0.896250\n",
      "dbow+dmc_infer : acc rate: 0.810800  auc_roc: 0.888118\n"
     ]
    }
   ],
   "source": [
    "for name, train_model in models_by_name.items():\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_features=0.85, n_jobs=-1)\n",
    "    clf_error_rate_for_model(rf_clf, train_model, name, train_docs, test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "Simple logistic regression is doing quite a good job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8) : acc rate: 0.822800  auc_roc: 0.904801\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)_infer : acc rate: 0.798000  auc_roc: 0.883578\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8) : acc rate: 0.895200  auc_roc: 0.960083\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)_infer : acc rate: 0.893600  auc_roc: 0.959221\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8) : acc rate: 0.846000  auc_roc: 0.917237\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)_infer : acc rate: 0.815600  auc_roc: 0.891742\n",
      "dbow+dmm : acc rate: 0.901600  auc_roc: 0.962566\n",
      "dbow+dmm_infer : acc rate: 0.899200  auc_roc: 0.960734\n",
      "dbow+dmc : acc rate: 0.894400  auc_roc: 0.961836\n",
      "dbow+dmc_infer : acc rate: 0.895200  auc_roc: 0.960089\n"
     ]
    }
   ],
   "source": [
    "for name, train_model in models_by_name.items():\n",
    "    lr_clf = LogisticRegression(n_jobs=-1)\n",
    "    clf_error_rate_for_model(lr_clf, train_model, name, train_docs, test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "# structrue\n",
    "n_input = 200\n",
    "n_hidden = 50\n",
    "n_output = 2\n",
    "\n",
    "# input\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "hidden = tf.layers.dense(X, n_hidden, activation=tf.tanh, name=\"hidden\")\n",
    "logits = tf.layers.dense(hidden, n_output, name=\"logits\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer(0.0005)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, tf.cast(tf.reshape(y, (-1,)), tf.int32), 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000, 200)\n"
     ]
    }
   ],
   "source": [
    "doc_model = models_by_name['dbow+dmc']\n",
    "\n",
    "train_targets = np.array([doc.sentiment for doc in train_docs])\n",
    "train_feats = np.array([doc_model.docvecs[doc.tags[0]] for doc in train_docs])\n",
    "\n",
    "print(train_targets.shape)\n",
    "print(train_feats.shape)\n",
    "\n",
    "train_dataset = np.array([{\"feats\": train_feats[idx], \"target\": train_targets[idx]} for idx in range(len(train_targets))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(iteration, batch_size):\n",
    "    if iteration == 0:\n",
    "        np.random.shuffle(train_dataset)\n",
    "    batch_dataset = train_dataset[iteration * batch_size : (iteration + 1) * batch_size]\n",
    "    X_batch = np.array([item[\"feats\"] for item in batch_dataset]).reshape(-1, n_input)\n",
    "    y_batch = np.array([item[\"target\"] for item in batch_dataset])\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100: loss: 0.312429, accuracy: 0.900000\n",
      "Step 200: loss: 0.242779, accuracy: 0.920000\n",
      "Step 300: loss: 0.298778, accuracy: 0.920000\n",
      "Step 400: loss: 0.252701, accuracy: 0.900000\n",
      "Epoch 0: loss: 0.168647, accuracy: 0.960000\n",
      "Step 25100: loss: 0.199757, accuracy: 0.940000\n",
      "Step 25200: loss: 0.249264, accuracy: 0.860000\n",
      "Step 25300: loss: 0.213603, accuracy: 0.920000\n",
      "Step 25400: loss: 0.243585, accuracy: 0.860000\n",
      "Epoch 1: loss: 0.203530, accuracy: 0.900000\n",
      "Step 50100: loss: 0.402180, accuracy: 0.880000\n",
      "Step 50200: loss: 0.179384, accuracy: 0.920000\n",
      "Step 50300: loss: 0.130244, accuracy: 0.940000\n",
      "Step 50400: loss: 0.387198, accuracy: 0.820000\n",
      "Epoch 2: loss: 0.242061, accuracy: 0.900000\n",
      "Step 75100: loss: 0.253615, accuracy: 0.860000\n",
      "Step 75200: loss: 0.149337, accuracy: 0.960000\n",
      "Step 75300: loss: 0.206783, accuracy: 0.940000\n",
      "Step 75400: loss: 0.487248, accuracy: 0.820000\n",
      "Epoch 3: loss: 0.162171, accuracy: 0.940000\n",
      "Step 100100: loss: 0.216643, accuracy: 0.900000\n",
      "Step 100200: loss: 0.193093, accuracy: 0.940000\n",
      "Step 100300: loss: 0.261329, accuracy: 0.880000\n",
      "Step 100400: loss: 0.179018, accuracy: 0.900000\n",
      "Epoch 4: loss: 0.304006, accuracy: 0.900000\n",
      "Step 125100: loss: 0.195314, accuracy: 0.920000\n",
      "Step 125200: loss: 0.114761, accuracy: 0.960000\n",
      "Step 125300: loss: 0.217689, accuracy: 0.900000\n",
      "Step 125400: loss: 0.351727, accuracy: 0.880000\n",
      "Epoch 5: loss: 0.138978, accuracy: 0.960000\n",
      "Step 150100: loss: 0.268487, accuracy: 0.880000\n",
      "Step 150200: loss: 0.275687, accuracy: 0.880000\n",
      "Step 150300: loss: 0.239494, accuracy: 0.900000\n",
      "Step 150400: loss: 0.268825, accuracy: 0.880000\n",
      "Epoch 6: loss: 0.289007, accuracy: 0.880000\n",
      "Step 175100: loss: 0.235871, accuracy: 0.920000\n",
      "Step 175200: loss: 0.258846, accuracy: 0.880000\n",
      "Step 175300: loss: 0.161593, accuracy: 0.960000\n",
      "Step 175400: loss: 0.262878, accuracy: 0.940000\n",
      "Epoch 7: loss: 0.188863, accuracy: 0.920000\n",
      "Step 200100: loss: 0.243352, accuracy: 0.920000\n",
      "Step 200200: loss: 0.408410, accuracy: 0.840000\n",
      "Step 200300: loss: 0.336672, accuracy: 0.860000\n",
      "Step 200400: loss: 0.263265, accuracy: 0.860000\n",
      "Epoch 8: loss: 0.187115, accuracy: 0.920000\n",
      "Step 225100: loss: 0.271800, accuracy: 0.920000\n",
      "Step 225200: loss: 0.240223, accuracy: 0.920000\n",
      "Step 225300: loss: 0.127015, accuracy: 0.960000\n",
      "Step 225400: loss: 0.365600, accuracy: 0.860000\n",
      "Epoch 9: loss: 0.266434, accuracy: 0.860000\n",
      "Step 250100: loss: 0.383064, accuracy: 0.900000\n",
      "Step 250200: loss: 0.518147, accuracy: 0.720000\n",
      "Step 250300: loss: 0.188254, accuracy: 0.920000\n",
      "Step 250400: loss: 0.304071, accuracy: 0.880000\n",
      "Epoch 10: loss: 0.232811, accuracy: 0.900000\n",
      "Step 275100: loss: 0.130802, accuracy: 0.960000\n",
      "Step 275200: loss: 0.197170, accuracy: 0.940000\n",
      "Step 275300: loss: 0.194385, accuracy: 0.920000\n",
      "Step 275400: loss: 0.274317, accuracy: 0.900000\n",
      "Epoch 11: loss: 0.206338, accuracy: 0.940000\n",
      "Step 300100: loss: 0.192254, accuracy: 0.900000\n",
      "Step 300200: loss: 0.244281, accuracy: 0.840000\n",
      "Step 300300: loss: 0.129806, accuracy: 0.960000\n",
      "Step 300400: loss: 0.194734, accuracy: 0.920000\n",
      "Epoch 12: loss: 0.239191, accuracy: 0.900000\n",
      "Step 325100: loss: 0.216455, accuracy: 0.900000\n",
      "Step 325200: loss: 0.237119, accuracy: 0.840000\n",
      "Step 325300: loss: 0.199271, accuracy: 0.880000\n",
      "Step 325400: loss: 0.219262, accuracy: 0.920000\n",
      "Epoch 13: loss: 0.149013, accuracy: 0.960000\n",
      "Step 350100: loss: 0.265767, accuracy: 0.860000\n",
      "Step 350200: loss: 0.252748, accuracy: 0.880000\n",
      "Step 350300: loss: 0.153652, accuracy: 0.940000\n",
      "Step 350400: loss: 0.234726, accuracy: 0.900000\n",
      "Epoch 14: loss: 0.233614, accuracy: 0.940000\n",
      "Step 375100: loss: 0.184882, accuracy: 0.900000\n",
      "Step 375200: loss: 0.292458, accuracy: 0.900000\n",
      "Step 375300: loss: 0.304457, accuracy: 0.880000\n",
      "Step 375400: loss: 0.221421, accuracy: 0.900000\n",
      "Epoch 15: loss: 0.242052, accuracy: 0.860000\n",
      "Step 400100: loss: 0.300549, accuracy: 0.860000\n",
      "Step 400200: loss: 0.238713, accuracy: 0.900000\n",
      "Step 400300: loss: 0.199404, accuracy: 0.880000\n",
      "Step 400400: loss: 0.339047, accuracy: 0.820000\n",
      "Epoch 16: loss: 0.176527, accuracy: 0.940000\n",
      "Step 425100: loss: 0.236148, accuracy: 0.900000\n",
      "Step 425200: loss: 0.228020, accuracy: 0.900000\n",
      "Step 425300: loss: 0.225619, accuracy: 0.920000\n",
      "Step 425400: loss: 0.258662, accuracy: 0.900000\n",
      "Epoch 17: loss: 0.373936, accuracy: 0.840000\n",
      "Step 450100: loss: 0.181943, accuracy: 0.940000\n",
      "Step 450200: loss: 0.194944, accuracy: 0.920000\n",
      "Step 450300: loss: 0.372443, accuracy: 0.860000\n",
      "Step 450400: loss: 0.239343, accuracy: 0.920000\n",
      "Epoch 18: loss: 0.257907, accuracy: 0.860000\n",
      "Step 475100: loss: 0.182495, accuracy: 0.940000\n",
      "Step 475200: loss: 0.197189, accuracy: 0.900000\n",
      "Step 475300: loss: 0.212225, accuracy: 0.900000\n",
      "Step 475400: loss: 0.221742, accuracy: 0.920000\n",
      "Epoch 19: loss: 0.464201, accuracy: 0.760000\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(train_targets) // batch_size):\n",
    "            X_batch, y_batch = get_train_batch(iteration, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "            if (iteration % 100 == 0) and (iteration != 0):\n",
    "                loss_eval, accuracy_eval = sess.run([loss, accuracy], feed_dict={X: X_batch, y: y_batch})\n",
    "                print(\"Step %d: loss: %.6f, accuracy: %.6f\" %(len(train_targets) * epoch + iteration, loss_eval, accuracy_eval))\n",
    "        \n",
    "        loss_eval, accuracy_eval = sess.run([loss, accuracy], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(\"Epoch %d: loss: %.6f, accuracy: %.6f\" %(epoch, loss_eval, accuracy_eval))\n",
    "    save_path = saver.save(sess, \"./my_imdb_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 510 ms, total: 1min 32s\n",
      "Wall time: 1min 31s\n",
      "(25000,)\n",
      "(25000, 200)\n"
     ]
    }
   ],
   "source": [
    "doc_model = models_by_name['dbow+dmc']\n",
    "\n",
    "test_targets = np.array([doc.sentiment for doc in test_docs])\n",
    "%time test_feats_infer = np.array([doc_model.infer_vector(doc.words, steps=3, alpha=0.1) for doc in test_docs])\n",
    "\n",
    "print(test_targets.shape)\n",
    "print(test_feats_infer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_imdb_model\n",
      "Computing final accuracy on the test set (this will take a while)...\n",
      "('Test accuracy:', 0.89304)\n"
     ]
    }
   ],
   "source": [
    "n_test_batches = 50\n",
    "X_test_batches = np.array_split(test_feats_infer, n_test_batches)\n",
    "y_test_batches = np.array_split(test_targets, n_test_batches)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_imdb_model\")\n",
    "\n",
    "    print(\"Computing final accuracy on the test set (this will take a while)...\")\n",
    "    acc_test = np.mean([\n",
    "        accuracy.eval(feed_dict={X: X_test_batch, y: y_test_batch})\n",
    "        for X_test_batch, y_test_batch in zip(X_test_batches, y_test_batches)])\n",
    "    print(\"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our testing, contrary to the results of the paper, PV-DBOW performs best.  \n",
    "Concatenating vectors from different models only offers a small predictive improvement over averaging vectors. There best results reproduced are just under 10% error rate, still a long way from the paper's reported 7.42% error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are inferred vectors close to the precalculated ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 95329...\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8):\n",
      " [(95329, 0.7945490479469299), (2911, 0.4073815643787384), (63358, 0.3943607211112976)]\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8):\n",
      " [(95329, 0.9538134336471558), (58788, 0.6186803579330444), (20746, 0.6146473288536072)]\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8):\n",
      " [(95329, 0.8836967945098877), (30224, 0.6142271757125854), (56893, 0.6125851273536682)]\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # Pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models:\n",
    "    inferred_docvec = model.infer_vector(alldocs[doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, here the stored vector from 20 epochs of training is usually one of the closest to a freshly-inferred vector for the same words.   \n",
    "Note the defaults for inference are very abbreviated â just 5 steps starting at a high alpha â and likely need tuning for other applications.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do close documents seem more related than distant ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (74844): Â«since today is steven spielberg's 60th birthday , i wanted to comment on one of his movies . he only produced \" young sherlock holmes \" - barry levinson directed it - but it's a pretty cool movie . portraying sherlock ( nicholas rowe ) and watson ( alan cox ) meeting in a boarding school while some strange murders are occurring in london , they do pretty much anything that they want . the whole movie has the definite feel of a spielberg movie , what with the burning of a giant set and all . even if the movie doesn't have the most impressive plot , the hallucinations make up for everything ( it's not often that we get to see cream puffs and chocolate Ã©clairs attack someone ; serves him right for eating junk food ! ) . i recommend it .Â»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8):\n",
      "\n",
      "MOST (36931, 0.4433958828449249): Â«hollywood is one of the best and the beautiful things that had occurred in my life . i admire and am very much fascinated by the way hollywood generates ideas and implement them . it makes me wonder about the scope of human brain . i saw flatliners a long time back but the story , direction , cast and of all acting is still fresh in my mind . the story begins with our lead actor sutherland saying during sunrise \" what a beautiful day to die . \" for all of us , it's a story which shows emotions that are sometimes withheld in our mind during our entire life . never able to understand few things in life . it shows us to get motivated and to improve our quality of life . anyway i suggest it to all that watch it once .Â»\n",
      "\n",
      "MEDIAN (6414, -7.133278995752335e-05): Â«\" 9/11 , \" hosted by robert deniro , presents footage from outside and inside the twin towers in new york , on september 11 , 2001 . never too grisly and gory , yet powerful and moving . \" 9/11 \" is a real treat . anyone not moved by this television show is immune to anything . 5/5 stars --Â»\n",
      "\n",
      "LEAST (56892, -0.364164263010025): Â«vh1 behind the music catapulted the rock documentary to a different level ( good or bad is your opinion ) however , the structure the vh1 producers use works wonders : rebellious teens , start band , plucked from obscurity and poverty by major label . rise fall and rise . good dramatic arcs \" fearless freaks' follows this formula a bit but has different ambitions , and mostly i think it succeeds . but some sloppy storytelling and an excessive running time hurt the film a bit . still there are moments of pure fascination , emotion and heartache in this one ( spoilers #1 ) 3 2 1 the heroin addiction scene with steve mentioned in previous posts becomes a frightening , depressing yet fascinating side note . even if one views this scene and has never heard the flaming lips . you will be moved . powerful stuff . thanks to both steve and the filmmakers courage to let the audience be moved by this very difficult intimate scene . however , somewhat like most of the lips earlier records , the film lacks direction and focus and becomes very vignette like . no real connective glue . maybe an editing issue ? ( spoiler #2 ) 3 2 1 example ? one part of the film mentions how band member steve had some members of this family commit suicide but doesn't come full circle with the story telling . they just drop that fragment . you don't know who . . . when . . . where . . . why . steve's girlfriend mentions it and the filmmakers just drop the whole thing . never tie it up . disappointing . example 2 ( spoilers ) 3 2 1 the film uses these psychedelic montages as breaking points for the story . come on people . you could have easily come up with a better transition device ( i am a video editor by trade so i think i can be critical of this flaw ) when the film doesn't drop the ball and effectively tells the stories of flaming lips members' families/relatives/siblings it can compete with any other human interest documentary out there . truly moving emotional stuff . so wrapping it up . a good not great film about a soon to be legendary semi cult band . and for music freaks like myself the film features interviews of gibby of butthole surfers , johnathan donahue from mercury rev , meg & jack white , beck , and some others . really cool end kdcÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = random.choice(simple_models)  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%d): Â«%sÂ»\\n' % (doc_id, ' '.join(alldocs[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: Â«%sÂ»\\n' % (label, sims[index], ' '.join(alldocs[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Somewhat, in terms of reviewer tone, movie genre, etc... the MOST cosine-similar docs usually seem more like the TARGET than the MEDIAN or LEAST.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the word vectors show useful similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_models = simple_models[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gensim.models.doc2vec.Doc2Vec at 0x7f8b06601c10>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x7f8b06601cd0>,\n",
       " <gensim.models.doc2vec.Doc2Vec at 0x7f8b069bea10>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar words for 'frustrated' (476 occurences)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saucecat/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8)</th><th>Doc2Vec(dbow,d100,n5,mc2,s0.001,t8)</th><th>Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8)</th></tr><tr><td>[(u'disturbed', 0.7746529579162598),<br>\n",
       "(u'depressed', 0.7320755124092102),<br>\n",
       "(u'confused', 0.706322431564331),<br>\n",
       "(u'disgusted', 0.7054495215415955),<br>\n",
       "(u'disillusioned', 0.7042022943496704),<br>\n",
       "(u'angry', 0.7025586366653442),<br>\n",
       "(u'bored', 0.7015896439552307),<br>\n",
       "(u'irritated', 0.6992833614349365),<br>\n",
       "(u'enraged', 0.6737393140792847),<br>\n",
       "(u'unimpressed', 0.6725138425827026),<br>\n",
       "(u'perplexed', 0.6615269780158997),<br>\n",
       "(u'jealous', 0.6610188484191895),<br>\n",
       "(u'annoyed', 0.6493697166442871),<br>\n",
       "(u'frightened', 0.6388447284698486),<br>\n",
       "(u'dissatisfied', 0.6363586187362671),<br>\n",
       "(u'distraught', 0.633137047290802),<br>\n",
       "(u'perturbed', 0.6268664598464966),<br>\n",
       "(u'nonplussed', 0.6229336857795715),<br>\n",
       "(u'troubled', 0.6206403970718384),<br>\n",
       "(u'impatient', 0.6191350221633911)]</td><td>[(u'organisation', 0.42548567056655884),<br>\n",
       "(u'mongolia', 0.39597493410110474),<br>\n",
       "(u\"asimov's\", 0.3929506838321686),<br>\n",
       "(u'eamon', 0.38869649171829224),<br>\n",
       "(u'sleez', 0.38152042031288147),<br>\n",
       "(u'refunded', 0.3796987533569336),<br>\n",
       "(u\"today's\", 0.3741285502910614),<br>\n",
       "(u'radhika', 0.3675813674926758),<br>\n",
       "(u'slides', 0.36348873376846313),<br>\n",
       "(u'mazar', 0.3630625009536743),<br>\n",
       "(u'babbitt', 0.36268505454063416),<br>\n",
       "(u'tonic', 0.36204156279563904),<br>\n",
       "(u'sec', 0.358733206987381),<br>\n",
       "(u'sullivan', 0.35872185230255127),<br>\n",
       "(u'effeminacy', 0.3576321005821228),<br>\n",
       "(u'magistrate', 0.35597896575927734),<br>\n",
       "(u'pere', 0.3558776378631592),<br>\n",
       "(u'radio/tv', 0.3516930341720581),<br>\n",
       "(u'kilometer', 0.35146278142929077),<br>\n",
       "(u'$50', 0.35077035427093506)]</td><td>[(u'confused', 0.6229063868522644),<br>\n",
       "(u'disturbed', 0.5801238417625427),<br>\n",
       "(u'irritated', 0.5658557415008545),<br>\n",
       "(u'depressed', 0.5652328729629517),<br>\n",
       "(u'disgusted', 0.5620701313018799),<br>\n",
       "(u'bored', 0.5554786324501038),<br>\n",
       "(u'repulsed', 0.5281217098236084),<br>\n",
       "(u'disillusioned', 0.5236408710479736),<br>\n",
       "(u'upset', 0.5170360207557678),<br>\n",
       "(u'motivated', 0.5022591352462769),<br>\n",
       "(u'satisfied', 0.501629650592804),<br>\n",
       "(u'jealous', 0.49524572491645813),<br>\n",
       "(u'angry', 0.4920088052749634),<br>\n",
       "(u'annoyed', 0.4907613694667816),<br>\n",
       "(u'engrossed', 0.48971816897392273),<br>\n",
       "(u'perplexed', 0.4884505271911621),<br>\n",
       "(u'unsatisfied', 0.4835604429244995),<br>\n",
       "(u'confounded', 0.4811770021915436),<br>\n",
       "(u'numb', 0.4778806269168854),<br>\n",
       "(u'impatient', 0.47536855936050415)]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from IPython.display import HTML\n",
    "\n",
    "# pick a random word with a suitable number of occurences\n",
    "while True:\n",
    "    word = random.choice(word_models[0].wv.index2word)\n",
    "    if word_models[0].wv.vocab[word].count > 10:\n",
    "        break\n",
    "        \n",
    "# or uncomment below line, to just pick a word from the relevant domain:\n",
    "#word = 'comedy/drama'\n",
    "similars_per_model = [str(model.most_similar(word, topn=20)).replace('), ','),<br>\\n') for model in word_models]\n",
    "similar_table = (\"<table><tr><th>\" +\n",
    "    \"</th><th>\".join([str(model) for model in word_models]) + \n",
    "    \"</th></tr><tr><td>\" +\n",
    "    \"</td><td>\".join(similars_per_model) +\n",
    "    \"</td></tr></table>\")\n",
    "print(\"most similar words for '%s' (%d occurences)\" % (word, simple_models[0].wv.vocab[word].count))\n",
    "HTML(similar_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the DBOW words look meaningless?  \n",
    "That's because the gensim DBOW model doesn't train word vectors â they remain at their random initialized values â unless you ask with the `dbow_words=1` initialization parameter.  \n",
    "Concurrent word-training slows DBOW mode significantly, and offers little improvement (and sometimes a little worsening) of the error rate on this IMDB sentiment-prediction task.   \n",
    "Words from DM models tend to show meaningfully similar words when there are many examples in the training data (as with 'plot' or 'actor'). (All DM modes inherently involve word vector training concurrent with doc vector training.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the word vectors from this dataset any good at analogies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dm/c,d100,n5,w5,mc2,s0.001,t8): 30.23% correct (3051 of 10094)\n",
      "Doc2Vec(dbow,d100,n5,mc2,s0.001,t8): 0.01% correct (1 of 10094)\n",
      "Doc2Vec(dm/m,d100,n5,w10,mc2,s0.001,t8): 32.13% correct (3243 of 10094)\n"
     ]
    }
   ],
   "source": [
    "# Download this file: https://github.com/nicholas-leonard/word2vec/blob/master/questions-words.txt\n",
    "# and place it in the local directory\n",
    "# Note: this takes many minutes\n",
    "if os.path.isfile('data/questions-words.txt'):\n",
    "    for model in word_models:\n",
    "        sections = model.accuracy('data/questions-words.txt')\n",
    "        correct, incorrect = len(sections[-1]['correct']), len(sections[-1]['incorrect'])\n",
    "        print('%s: %0.2f%% correct (%d of %d)' % (model, float(correct*100)/(correct+incorrect), correct, correct+incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is a tiny, domain-specific dataset, it shows some meager capability on the general word analogies â at least for the DM/concat and DM/mean models which actually train word vectors. (The untrained random-initialized words of the DBOW model of course fail miserably.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
