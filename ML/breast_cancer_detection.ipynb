{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easily Build a Neural Net for Breast Cancer detection\n",
    "http://www.laurencemoroney.com/easily-build-a-neural-net-for-breast-cancer-detection/  \n",
    "In this case, we’ll work with structured data, represented as a CSV file. This has been generated from close inspection of the images of cells that were taken in a biopsy.\n",
    "  \n",
    "It’s also possible to work with the images directly, but we chose this approach — so you can modify this code for a problem you care about — because while you may not work on cancer detection, you likely have some structured data of your own, and hopefully the techniques we use here will work for you, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saucecat/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether GPU is fine :)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n"
     ]
    }
   ],
   "source": [
    "my_data = pd.read_csv('data/wdbc.csv', delimiter=',')\n",
    "print my_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'diagnosis', 'diagnosis_numeric', 'radius', 'texture',\n",
       "       'perimeter', 'area', 'smoothness', 'compactness', 'concavity',\n",
       "       'concave_points', 'symmetry', 'fractal_dimension', 'radius_se',\n",
       "       'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave_points_se',\n",
       "       'symmetry_se', 'fractal_dimension_se', 'radius_worse',\n",
       "       'texture_worst', 'perimeter_worst', 'area_worst',\n",
       "       'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
       "       'concave_points_worst', 'symmetry_worst',\n",
       "       'fractal_dimension_worst'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           int64\n",
       "diagnosis                   object\n",
       "diagnosis_numeric            int64\n",
       "radius                     float64\n",
       "texture                    float64\n",
       "perimeter                  float64\n",
       "area                       float64\n",
       "smoothness                 float64\n",
       "compactness                float64\n",
       "concavity                  float64\n",
       "concave_points             float64\n",
       "symmetry                   float64\n",
       "fractal_dimension          float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave_points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worse               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave_points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_numeric</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worse</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8510426</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>...</td>\n",
       "      <td>15.110</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.17730</td>\n",
       "      <td>0.23900</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8510653</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>0.04568</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500</td>\n",
       "      <td>20.49</td>\n",
       "      <td>96.09</td>\n",
       "      <td>630.5</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.18900</td>\n",
       "      <td>0.07283</td>\n",
       "      <td>0.3184</td>\n",
       "      <td>0.08183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8510824</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "      <td>273.9</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.06492</td>\n",
       "      <td>0.02956</td>\n",
       "      <td>...</td>\n",
       "      <td>10.230</td>\n",
       "      <td>15.66</td>\n",
       "      <td>65.13</td>\n",
       "      <td>314.9</td>\n",
       "      <td>0.13240</td>\n",
       "      <td>0.11480</td>\n",
       "      <td>0.08867</td>\n",
       "      <td>0.06227</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854941</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.02562</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85713702</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "      <td>201.9</td>\n",
       "      <td>0.08600</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.01588</td>\n",
       "      <td>...</td>\n",
       "      <td>8.964</td>\n",
       "      <td>21.96</td>\n",
       "      <td>57.26</td>\n",
       "      <td>242.2</td>\n",
       "      <td>0.12970</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.06880</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.07409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  diagnosis_numeric  radius  texture  perimeter   area  \\\n",
       "0   8510426         B                  0  13.540    14.36      87.46  566.3   \n",
       "1   8510653         B                  0  13.080    15.71      85.63  520.0   \n",
       "2   8510824         B                  0   9.504    12.44      60.34  273.9   \n",
       "3    854941         B                  0  13.030    18.42      82.61  523.8   \n",
       "4  85713702         B                  0   8.196    16.84      51.71  201.9   \n",
       "\n",
       "   smoothness  compactness  concavity           ...             radius_worse  \\\n",
       "0     0.09779      0.08129    0.06664           ...                   15.110   \n",
       "1     0.10750      0.12700    0.04568           ...                   14.500   \n",
       "2     0.10240      0.06492    0.02956           ...                   10.230   \n",
       "3     0.08983      0.03766    0.02562           ...                   13.300   \n",
       "4     0.08600      0.05943    0.01588           ...                    8.964   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          19.26            99.70       711.2           0.14400   \n",
       "1          20.49            96.09       630.5           0.13120   \n",
       "2          15.66            65.13       314.9           0.13240   \n",
       "3          22.81            84.46       545.9           0.09701   \n",
       "4          21.96            57.26       242.2           0.12970   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  \\\n",
       "0            0.17730          0.23900               0.12880          0.2977   \n",
       "1            0.27760          0.18900               0.07283          0.3184   \n",
       "2            0.11480          0.08867               0.06227          0.2450   \n",
       "3            0.04619          0.04833               0.05013          0.1987   \n",
       "4            0.13570          0.06880               0.02564          0.3105   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.07259  \n",
       "1                  0.08183  \n",
       "2                  0.07773  \n",
       "3                  0.06169  \n",
       "4                  0.07409  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data needs to be split into a training set and a test set\n",
    "# To use 80/20, set the training size to .8\n",
    "training_set_size_portion = .8\n",
    "\n",
    "# Set to True to shuffle the data before you split into training and test sets\n",
    "do_shuffle = True\n",
    "\n",
    "# Keep track of the accuracy score\n",
    "accuracy_score = 0\n",
    "\n",
    "# The DNN has hidden units, set the spec for them here\n",
    "hidden_units_spec = [10,20,10]\n",
    "n_classes_spec = 2\n",
    "\n",
    "# Define the temp directory for keeping the model and checkpoints\n",
    "tmp_dir_spec = \"tmp/model\"\n",
    "\n",
    "# The number of training steps\n",
    "steps_spec = 2000\n",
    "\n",
    "# The number of epochs\n",
    "epochs_spec = 15\n",
    "\n",
    "# Here's a set of our features. If you look at the CSV, \n",
    "# you'll see these are the names of the columns. \n",
    "# In this case, we'll just use all of them:\n",
    "#features = ['radius','texture']\n",
    "features = my_data.columns.values[3:]\n",
    "\n",
    "# Here's the label that we want to predict -- it's also a column in the CSV\n",
    "labels = ['diagnosis_numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['radius', 'texture', 'perimeter', 'area', 'smoothness',\n",
       "       'compactness', 'concavity', 'concave_points', 'symmetry',\n",
       "       'fractal_dimension', 'radius_se', 'texture_se', 'perimeter_se',\n",
       "       'area_se', 'smoothness_se', 'compactness_se', 'concavity_se',\n",
       "       'concave_points_se', 'symmetry_se', 'fractal_dimension_se',\n",
       "       'radius_worse', 'texture_worst', 'perimeter_worst', 'area_worst',\n",
       "       'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
       "       'concave_points_worst', 'symmetry_worst',\n",
       "       'fractal_dimension_worst'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test sets based on our specified columns\n",
    "\n",
    "Your data might have some form of ordering on it already, and this could impact the learning/testing.   \n",
    "For example, if it’s breast cancer, sorted by size, and the items at the beginning are more likely to be benign, and the ones at the end are more likely to be malignant, then you’ll be training on benign data, and testing on malignant, which isn’t representative.   \n",
    "It’s always a good idea to shuffle your data before you split it into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pandas DataFrame allows you to shuffle with the reindex method\n",
    "# Docs: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex\n",
    "# If the doShuffle property is true, we will shuffle with this\n",
    "# You really SHOULD shuffle to make sure that trends in data don't affect your learning\n",
    "# but I make it optional here so you can choose\n",
    "\n",
    "if do_shuffle:\n",
    "    randomized_data = my_data.reindex(np.random.permutation(my_data.index))\n",
    "else:\n",
    "    randomized_data = my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_numeric</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worse</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>906290</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>11.160</td>\n",
       "      <td>21.41</td>\n",
       "      <td>70.95</td>\n",
       "      <td>380.3</td>\n",
       "      <td>0.10180</td>\n",
       "      <td>0.05978</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>...</td>\n",
       "      <td>12.360</td>\n",
       "      <td>28.92</td>\n",
       "      <td>79.26</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.11080</td>\n",
       "      <td>0.03582</td>\n",
       "      <td>0.04306</td>\n",
       "      <td>0.2976</td>\n",
       "      <td>0.07123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>91504</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>13.820</td>\n",
       "      <td>24.49</td>\n",
       "      <td>92.33</td>\n",
       "      <td>595.9</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.16810</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>...</td>\n",
       "      <td>16.010</td>\n",
       "      <td>32.94</td>\n",
       "      <td>106.00</td>\n",
       "      <td>788.0</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.39660</td>\n",
       "      <td>0.33810</td>\n",
       "      <td>0.15210</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.11830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.026850</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>924342</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>9.333</td>\n",
       "      <td>21.94</td>\n",
       "      <td>59.01</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>0.05605</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>...</td>\n",
       "      <td>9.845</td>\n",
       "      <td>25.05</td>\n",
       "      <td>62.86</td>\n",
       "      <td>295.8</td>\n",
       "      <td>0.1103</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.07993</td>\n",
       "      <td>0.02564</td>\n",
       "      <td>0.2435</td>\n",
       "      <td>0.07393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>866083</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>13.610</td>\n",
       "      <td>24.69</td>\n",
       "      <td>87.76</td>\n",
       "      <td>572.6</td>\n",
       "      <td>0.09258</td>\n",
       "      <td>0.07862</td>\n",
       "      <td>0.052850</td>\n",
       "      <td>...</td>\n",
       "      <td>16.890</td>\n",
       "      <td>35.64</td>\n",
       "      <td>113.20</td>\n",
       "      <td>848.7</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.28840</td>\n",
       "      <td>0.37960</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>0.07900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  diagnosis_numeric  radius  texture  perimeter   area  \\\n",
       "242  906290         B                  0  11.160    21.41      70.95  380.3   \n",
       "552   91504         M                  1  13.820    24.49      92.33  595.9   \n",
       "502  892189         M                  1  11.760    18.14      75.00  431.1   \n",
       "347  924342         B                  0   9.333    21.94      59.01  264.0   \n",
       "430  866083         M                  1  13.610    24.69      87.76  572.6   \n",
       "\n",
       "     smoothness  compactness  concavity           ...             \\\n",
       "242     0.10180      0.05978   0.008955           ...              \n",
       "552     0.11620      0.16810   0.135700           ...              \n",
       "502     0.09968      0.05914   0.026850           ...              \n",
       "347     0.09240      0.05605   0.039960           ...              \n",
       "430     0.09258      0.07862   0.052850           ...              \n",
       "\n",
       "     radius_worse  texture_worst  perimeter_worst  area_worst  \\\n",
       "242        12.360          28.92            79.26       458.0   \n",
       "552        16.010          32.94           106.00       788.0   \n",
       "502        13.360          23.39            85.10       553.6   \n",
       "347         9.845          25.05            62.86       295.8   \n",
       "430        16.890          35.64           113.20       848.7   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "242            0.1282            0.11080          0.03582   \n",
       "552            0.1794            0.39660          0.33810   \n",
       "502            0.1137            0.07974          0.06120   \n",
       "347            0.1103            0.08298          0.07993   \n",
       "430            0.1471            0.28840          0.37960   \n",
       "\n",
       "     concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "242               0.04306          0.2976                  0.07123  \n",
       "552               0.15210          0.3651                  0.11830  \n",
       "502               0.07160          0.1978                  0.06915  \n",
       "347               0.02564          0.2435                  0.07393  \n",
       "430               0.13290          0.3470                  0.07900  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = len(randomized_data)\n",
    "training_set_size = int(total_records * training_set_size_portion)\n",
    "test_set_size = total_records - training_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius  texture  perimeter   area  smoothness  compactness  concavity  \\\n",
      "242  11.160    21.41      70.95  380.3     0.10180      0.05978   0.008955   \n",
      "552  13.820    24.49      92.33  595.9     0.11620      0.16810   0.135700   \n",
      "502  11.760    18.14      75.00  431.1     0.09968      0.05914   0.026850   \n",
      "347   9.333    21.94      59.01  264.0     0.09240      0.05605   0.039960   \n",
      "430  13.610    24.69      87.76  572.6     0.09258      0.07862   0.052850   \n",
      "\n",
      "     concave_points  symmetry  fractal_dimension           ...             \\\n",
      "242         0.01076    0.1615            0.06144           ...              \n",
      "552         0.06759    0.2275            0.07237           ...              \n",
      "502         0.03515    0.1619            0.06287           ...              \n",
      "347         0.01282    0.1692            0.06576           ...              \n",
      "430         0.03085    0.1761            0.06130           ...              \n",
      "\n",
      "     radius_worse  texture_worst  perimeter_worst  area_worst  \\\n",
      "242        12.360          28.92            79.26       458.0   \n",
      "552        16.010          32.94           106.00       788.0   \n",
      "502        13.360          23.39            85.10       553.6   \n",
      "347         9.845          25.05            62.86       295.8   \n",
      "430        16.890          35.64           113.20       848.7   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "242            0.1282            0.11080          0.03582   \n",
      "552            0.1794            0.39660          0.33810   \n",
      "502            0.1137            0.07974          0.06120   \n",
      "347            0.1103            0.08298          0.07993   \n",
      "430            0.1471            0.28840          0.37960   \n",
      "\n",
      "     concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "242               0.04306          0.2976                  0.07123  \n",
      "552               0.15210          0.3651                  0.11830  \n",
      "502               0.07160          0.1978                  0.06915  \n",
      "347               0.02564          0.2435                  0.07393  \n",
      "430               0.13290          0.3470                  0.07900  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "     diagnosis_numeric\n",
      "242                  0\n",
      "552                  1\n",
      "502                  1\n",
      "347                  0\n",
      "430                  1\n"
     ]
    }
   ],
   "source": [
    "# Build the training features and labels\n",
    "training_features = randomized_data.head(training_set_size)[features].copy()\n",
    "training_labels = randomized_data.head(training_set_size)[labels].copy()\n",
    "print(training_features.head())\n",
    "print(training_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the testing features and labels\n",
    "testing_features = randomized_data.tail(test_set_size)[features].copy()\n",
    "testing_labels = randomized_data.tail(test_set_size)[labels].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow Feature Columns\n",
    "The Neural Network classifier expects the feature columns to be specified as tf.feature_column types.   \n",
    "As our columns are numbers,  we set them to numeric_column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key) for key in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='radius', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='texture', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='perimeter', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='area', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='smoothness', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='compactness', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='concavity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='concave_points', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='symmetry', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='fractal_dimension', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='radius_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='texture_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='perimeter_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='area_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='smoothness_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='compactness_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='concavity_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='concave_points_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='symmetry_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='fractal_dimension_se', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='radius_worse', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='texture_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='perimeter_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='area_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='smoothness_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='compactness_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='concavity_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='concave_points_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='symmetry_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='fractal_dimension_worst', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network used to classify the data\n",
    "Given that we have all our data, we can now create our neural network object that we’ll train on the data. This takes the feature columns that you just created as well as parameters defining the number of hidden units in the neural network, as well as the number of classes. As it trains the network, it saves temporary files and checkpoints as well as the finished model out to the specified model directory.  \n",
    "\n",
    "The hidden units are a direct specification of what the network looks like — so, for example our default here is [10, 20, 10], which means there’ll be a layer of 10 neurons, with each connected to 20 neurons in the next layer, each of which is connected to 10 neurons in the third layer.   \n",
    "\n",
    "The classes are the number of classes we are classifying to. In this case we’re doing breast cancer classification, with 2 classes, so we will train on 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efcc7771a10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'tmp/model', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=hidden_units_spec, \n",
    "                                        n_classes=n_classes_spec, model_dir=tmp_dir_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "The next step is to train the classifier using the data. to do this you build an input function that specifies the features (aka ‘x’) and the labels (aka ‘y’). This is done by specifiying it as a pandas_input_fn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training input function\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(x=training_features, y=training_labels, num_epochs=epochs_spec, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can train the neural network by giving it the input function, and the number of steps you want to use to train it.   \n",
    "Experiment with different step numbers to get different results. In the case of the breast cancer data, with 2000 steps, I usually get 90%+ accuracy against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into tmp/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 513.96954, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 54 into tmp/model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.5733595.\n",
      "CPU times: user 1.92 s, sys: 72.5 ms, total: 1.99 s\n",
      "Wall time: 1.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7efcc46c96d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model using the classifer.\n",
    "classifier.train(input_fn=train_input_fn, steps=steps_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network\n",
    "Similar to training a model, we test the model by specifying an input function in exactly the same way, except of course we pass in the testing features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test input function\n",
    "test_input_fn = tf.estimator.inputs.pandas_input_fn(x=testing_features, y=testing_labels, num_epochs=epochs_spec, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can ask the classifier to tell evaluate the test input function, and tell us its accuracy. It goes through the test set, and compares its classifications to the actual values, and uses this to calculate how often it was right, giving us an accuracy score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-10-04:21:02\n",
      "INFO:tensorflow:Restoring parameters from tmp/model/model.ckpt-54\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-10-04:21:02\n",
      "INFO:tensorflow:Saving dict for global step 54: accuracy = 0.877193, accuracy_baseline = 0.5526316, auc = 0.9486461, auc_precision_recall = 0.9511447, average_loss = 0.3304201, global_step = 54, label/mean = 0.4473684, loss = 40.358456, prediction/mean = 0.36682603\n",
      "Accuracy = 0.877192974091\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "print(\"Accuracy = {}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use the network\n",
    "Now that you have a trained and tested network, you likely want to see how it would react to predict different data sets that it hasn’t already seen. Let’s take a look at how to do that, and read the results here.  \n",
    "\n",
    "First of all, your prediction set should match your feature columns. So, in this example we only trained against 2 feature columns, and they were both numeric. So, if I want to classify something, I have to pass data in the same shape into the network. So, for example, here I can create a prediction set of two cells, one with a radius of 14 and a texture of 25, the other with a radius of 13 and a texture of 26.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prediction set -- this is a list of input features that you want to classify\n",
    "prediction_set = pd.DataFrame({'radius':[14, 13], 'texture':[25, 26]})\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(x=prediction_set, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Get a list of the predictions\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "\n",
    "predicted_classes = [p[\"classes\"] for p in predictions] \n",
    "results=np.concatenate(predicted_classes) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "You’ve done a lot in a very short time — not only have you trained a neural network to classify breast cancer data from the Wisconsin database, as well as writing code that can be easily adapted to provide classification for any CSV file (within reason). Take it for a spin, and let me know your experience in the comments below!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
