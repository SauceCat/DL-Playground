{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saucecat/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras layers\n",
    "from keras.layers import Input, Activation, Add\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.core import Dense, Flatten, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# keras model\n",
    "from keras.models import Model\n",
    "\n",
    "# others\n",
    "from deblur.utils.layer_utils import ReflectionPadding2D, res_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the paper defined hyper-parameter:chr\n",
    "channel_rate = 64\n",
    "# Note the image_shape must be multiple of patch_shape\n",
    "image_shape = (256, 256, 3)\n",
    "patch_shape = (channel_rate, channel_rate, 3)\n",
    "\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "input_shape_generator = (256, 256, input_nc)\n",
    "input_shape_discriminator = (256, 256, output_nc)\n",
    "n_blocks_gen = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/model.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    inputs = Input(shape=image_shape)\n",
    "    \n",
    "    x = ReflectionPadding2D((3, 3))(inputs)\n",
    "    x = Conv2D(filters=ngf, kernel_size=(7, 7), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    n_downsampling = 2\n",
    "    for i in range(n_downsampling):\n",
    "        mult = 2 ** i\n",
    "        x = Conv2D(filters=ngf * mult * 2, kernel_size=(3, 3), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "    mult = 2 ** n_downsampling\n",
    "    for i in range(n_blocks_gen):\n",
    "        x = res_block(x, ngf * mult, use_dropout=True)\n",
    "        \n",
    "    for i in range(n_downsampling):\n",
    "        mult = 2**(n_downsampling - i)\n",
    "        x = Conv2DTranspose(filters=int(ngf * mult / 2), kernel_size=(3, 3), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "    x = ReflectionPadding2D((3, 3))(x)\n",
    "    x = Conv2D(filters=output_nc, kernel_size=(7, 7), padding='valid')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    \n",
    "    outputs = Add()([x, inputs])\n",
    "    outputs = Lambda(lambda z: z/2)(outputs)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_1 (Reflect (None, 262, 262, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 9472        reflection_padding2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 128 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 256)  295168      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_2 (Reflect (None, 66, 66, 256)  0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  590080      reflection_padding2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 256)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_3 (Reflect (None, 66, 66, 256)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      reflection_padding2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_4 (Reflect (None, 66, 66, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      reflection_padding2d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_5 (Reflect (None, 66, 66, 256)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      reflection_padding2d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           add_1[0][0]                      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_6 (Reflect (None, 66, 66, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 256)  590080      reflection_padding2d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 256)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_7 (Reflect (None, 66, 66, 256)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 256)  590080      reflection_padding2d_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 256)  0           add_2[0][0]                      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_8 (Reflect (None, 66, 66, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 64, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_9 (Reflect (None, 66, 66, 256)  0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 256)  0           add_3[0][0]                      \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_10 (Reflec (None, 66, 66, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 64, 256)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_11 (Reflec (None, 66, 66, 256)  0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 256)  0           add_4[0][0]                      \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_12 (Reflec (None, 66, 66, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 64, 256)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_13 (Reflec (None, 66, 66, 256)  0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 256)  0           add_5[0][0]                      \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_14 (Reflec (None, 66, 66, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 256)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_15 (Reflec (None, 66, 66, 256)  0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 256)  0           add_6[0][0]                      \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_16 (Reflec (None, 66, 66, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 256)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_17 (Reflec (None, 66, 66, 256)  0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 256)  0           add_7[0][0]                      \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_18 (Reflec (None, 66, 66, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64, 64, 256)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_19 (Reflec (None, 66, 66, 256)  0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 256)  590080      reflection_padding2d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 64, 256)  0           add_8[0][0]                      \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 128 295040      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 128 512         conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 128 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 64) 73792       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256, 256, 64) 256         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 64) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reflection_padding2d_20 (Reflec (None, 262, 262, 64) 0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 3)  9411        reflection_padding2d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 3)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 256, 256, 3)  0           activation_15[0][0]              \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256, 256, 3)  0           add_10[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 11,399,171\n",
      "Trainable params: 11,388,675\n",
      "Non-trainable params: 10,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator_model()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    \"\"\"Build discriminator architecture.\"\"\"\n",
    "    n_layers, use_sigmoid = 3, False\n",
    "    inputs = Input(shape=input_shape_discriminator)\n",
    "\n",
    "    x = Conv2D(filters=ndf, kernel_size=(4, 4), strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult, nf_mult_prev = 1, 1\n",
    "    for n in range(n_layers):\n",
    "        nf_mult_prev, nf_mult = nf_mult, min(2**n, 8)\n",
    "        x = Conv2D(filters=ndf*nf_mult, kernel_size=(4, 4), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult_prev, nf_mult = nf_mult, min(2**n_layers, 8)\n",
    "    x = Conv2D(filters=ndf*nf_mult, kernel_size=(4, 4), strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(filters=1, kernel_size=(4, 4), strides=1, padding='same')(x)\n",
    "    if use_sigmoid:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='tanh')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x, name='Discriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 128, 128, 64)      3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 64, 64, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 256)       524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 1)         8193      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 3,098,370\n",
      "Trainable params: 3,096,450\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d = discriminator_model()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator containing discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    inputs = Input(shape=image_shape)\n",
    "    generated_image = generator(inputs)\n",
    "    outputs = discriminator(generated_image)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def generator_containing_discriminator_multiple_outputs(generator, discriminator):\n",
    "    inputs = Input(shape=image_shape)\n",
    "    generated_image = generator(inputs)\n",
    "    outputs = discriminator(generated_image)\n",
    "    model = Model(inputs=inputs, outputs=[generated_image, outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "Generator (Model)            (None, 256, 256, 3)       11399171  \n",
      "_________________________________________________________________\n",
      "Discriminator (Model)        (None, 1)                 3098370   \n",
      "=================================================================\n",
      "Total params: 14,497,541\n",
      "Trainable params: 14,485,125\n",
      "Non-trainable params: 12,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = generator_containing_discriminator(generator_model(), discriminator_model())\n",
    "m.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
